{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Learning objectives\n",
                "- Understand and apply Experimental Design (ED) techniques, including:\n",
                "    - Univariate feature selection based on $\\chi^2$-test and Mutual Information\n",
                "    - Alternative evaluation methods to holdout: $k-$-fold Cross Validation and Bootstrapping\n",
                "    - Alternative performance metrics to accuracy for classification: recall, precision, F1\n",
                "- A demonstration of the imbalanced classification problem and ED solutions to it"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Univariate feature selection\n",
                "## \u003cu\u003eConcept: Feature filtering based on $\\chi^2$-Test for classification\u003c/u\u003e\n",
                "\n",
                "Consider the following binary class problem:\n",
                "\n",
                "| HighSales | HasSequel | IsPopular |\n",
                "|-------------------|--------------------|------------------|\n",
                "| T                 | F                  | +                |\n",
                "| T                 | T                  | +                |\n",
                "| T                 | T                  | +                |\n",
                "| T                 | F                  | -                |\n",
                "| T                 | T                  | +                |\n",
                "| F                 | F                  | -                |\n",
                "| F                 | F                  | -                |\n",
                "| F                 | F                  | -                |\n",
                "| T                 | T                  | -                |\n",
                "| F                 | F                  | -                |\n",
                "\n",
                "Here, we wish to predict if `IsPopular` (the _class label_) given `HighSales` (sold many tickets) and `HasSequel` (has a sequel). For the following questions, we want to select the feature that best predicts whether or not the movie is Popular using the $\\chi^2$-Test.\n",
                "\n",
                "- Hypothesis testing is one way of statistically testing the significance of a feature or value.\n",
                "- In this example, we are calculating the $\\chi^2$ values of our feature `\"HighSales\"` w.r.t (with respect to) our class label `\"IsPopular\"`.\n",
                "\n",
                "To create a hypothesis test, we propose the following:\n",
                "1. Null Hypothesis: The feature is is not significant. In other words, the feature is useless and doesn't provide anything useful.\n",
                "2. Alternative Hypothesis: The feature is significant and provides useful insight statistically.\n",
                "\n",
                "To find out what hypothesis holds, we need to compute the `p-value`.\n",
                "\n",
                "**So what's the p-value?**\n",
                "- The `p-value` is the *probability* of obtaining results that are *at least as extreme* (i.e outliers) as the results observed.\n",
                "- These observations are under the assumption that the Null hypothesis is correct (the feature is useless).\n",
                "- However, if the `p-value` is small, then it means that our *observed extreme results* are very unlikely under the Null hypothesis. \n",
                "- Therefore, given some significance threshold $\\alpha$ (usually at 0.05), we **reject the Null hypothesis** i.f.f (if and only if) the `p-value` \u003c $\\alpha$."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cblockquote style=\"padding: 10px; background-color: #FFD392;\"\u003e\n",
                "\n",
                "   \n",
                "## Individual Exercise 1 (By Hand)\n",
                "Do the following questions by hand (without code):\n",
                "1. Compute the Observed and Expected contingency tables for `HighSales`. \n",
                "2. Calculate the $\\chi^2$(`HighSales`, `IsPopular`) value. To do so, you will also need to find out the \\textit{degrees of freedom (DoF)}.\n",
                "3. Conclude whether `HighSales` is independent of `IsPopular` at the $\\alpha=0.05$ significance level (p-value less than $\\alpha=0.05$). Use the table below for your calculations.\n",
                "    \n",
                "| DoF | $\\alpha$=0.05 | $\\alpha$=0.01 | $\\alpha$=0.001 |\n",
                "|-----|---------------|---------------|----------------|\n",
                "| 1   | 3.84          | 6.64          | 10.83          |\n",
                "| 2   | 5.99          | 9.21          | 13.82          |\n",
                "| 3   | 7.82          | 11.35         | 16.27          |\n",
                "| 4   | 9.49          | 13.28         | 18.47          |\n",
                "| 5   | 11.07         | 15.09         | 20.52          |\n",
                "| 6   | 12.59         | 16.81         | 22.46          |\n",
                "\n",
                "4. Repeat the process for `HasSequel` and decide which feature could be best used for predicting `IsPopular`."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we have worked it out by hand, let's implement the same approach using Python code. If you're planning to conduct feature selection using the $\\chi^2$-Test for your group project, you should follow through with this code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from matplotlib import pyplot as plt\n",
                "\n",
                "import scipy.stats as stats\n",
                "\n",
                "from scipy.stats import chi2_contingency"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "\u003cdiv\u003e\n",
                            "\u003cstyle scoped\u003e\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "\u003c/style\u003e\n",
                            "\u003ctable border=\"1\" class=\"dataframe\"\u003e\n",
                            "  \u003cthead\u003e\n",
                            "    \u003ctr style=\"text-align: right;\"\u003e\n",
                            "      \u003cth\u003e\u003c/th\u003e\n",
                            "      \u003cth\u003eHighSales\u003c/th\u003e\n",
                            "      \u003cth\u003eHasSequel\u003c/th\u003e\n",
                            "      \u003cth\u003eIsPopular\u003c/th\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "  \u003c/thead\u003e\n",
                            "  \u003ctbody\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e0\u003c/th\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e1\u003c/th\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e2\u003c/th\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e3\u003c/th\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e4\u003c/th\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e5\u003c/th\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e6\u003c/th\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e7\u003c/th\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e8\u003c/th\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e9\u003c/th\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "  \u003c/tbody\u003e\n",
                            "\u003c/table\u003e\n",
                            "\u003c/div\u003e"
                        ],
                        "text/plain": [
                            "   HighSales  HasSequel  IsPopular\n",
                            "0          1          0          1\n",
                            "1          1          1          1\n",
                            "2          1          1          1\n",
                            "3          1          0          0\n",
                            "4          1          1          1\n",
                            "5          0          0          0\n",
                            "6          0          0          0\n",
                            "7          0          0          0\n",
                            "8          1          1          0\n",
                            "9          0          0          0"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# this is the same table of data from above \n",
                "data = pd.DataFrame([[1,0,1], [1,1,1], [1,1,1], [1,0,0], [1,1,1], [0,0,0], [0,0,0], [0,0,0], [1,1,0], [0,0,0]], \n",
                "                    columns=['HighSales','HasSequel','IsPopular'])\n",
                "\n",
                "data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set our alpha significance level\n",
                "ALPHA = 0.05\n",
                "\n",
                "# get our features and class label\n",
                "features = data[['HighSales','HasSequel']]\n",
                "class_label = data['IsPopular']"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we have worked it out by hand, let's implement the same approach using Python code. If you're planning to conduct feature selection using the $\\chi^2$-Test for your group project, you should follow through with this code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "\u003cdiv\u003e\n",
                            "\u003cstyle scoped\u003e\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "\u003c/style\u003e\n",
                            "\u003ctable border=\"1\" class=\"dataframe\"\u003e\n",
                            "  \u003cthead\u003e\n",
                            "    \u003ctr style=\"text-align: right;\"\u003e\n",
                            "      \u003cth\u003eHighSales\u003c/th\u003e\n",
                            "      \u003cth\u003e0\u003c/th\u003e\n",
                            "      \u003cth\u003e1\u003c/th\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003eIsPopular\u003c/th\u003e\n",
                            "      \u003cth\u003e\u003c/th\u003e\n",
                            "      \u003cth\u003e\u003c/th\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "  \u003c/thead\u003e\n",
                            "  \u003ctbody\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e0\u003c/th\u003e\n",
                            "      \u003ctd\u003e4\u003c/td\u003e\n",
                            "      \u003ctd\u003e2\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e1\u003c/th\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "      \u003ctd\u003e4\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "  \u003c/tbody\u003e\n",
                            "\u003c/table\u003e\n",
                            "\u003c/div\u003e"
                        ],
                        "text/plain": [
                            "HighSales  0  1\n",
                            "IsPopular      \n",
                            "0          4  2\n",
                            "1          0  4"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "cont_table = pd.crosstab(class_label, features['HighSales'])\n",
                "cont_table"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we can use `stats.chi2_contigency(contingency_table, correction=False)` to get the $\\chi^2$-Test Statistic, `p-value`, the Degrees-of-Freedom, and the Expected values. \n",
                "\n",
                "The `correction=False` flag is to disable Yates' correction for continuity when there is 1 degree-of-freedom (out of scope for this subject)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "4.444444444444445\n0.03501498101966245\n1\n[[2.4 3.6]\n [1.6 2.4]]\n"
                }
            ],
            "source": [
                "chi2_val, p, dof, expected_values = stats.chi2_contingency(cont_table.values, correction=False)\n",
                "print(chi2_val)\n",
                "print(p)\n",
                "print(dof)\n",
                "\n",
                "# this is the expected values for the Chi^2 test\n",
                "print(expected_values)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "From above, we can see that our `p-value` is $\\approx0.035$ which is less than $\\alpha=0.05$. Therefore, we would **reject the Null Hypothesis**.\n",
                "\n",
                "To do both `HighSales` and `HasSequel` together, we can use a `for` loop as shown below:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Chi2 value for feature \"HighSales\": 4.4444\nReject the Null Hypothesis for feature \"HighSales\", p-value 0.0350\n\nChi2 value for feature \"HasSequel\": 3.4028\nFail to reject the Null Hypothesis for feature \"HasSequel\", p-value 0.0651\n\nFeature set after filtering with Chi-square test: ['HighSales']\n"
                }
            ],
            "source": [
                "filtered_features = []\n",
                "\n",
                "for feature in ('HighSales','HasSequel'):\n",
                "    cont_table = pd.crosstab(class_label, features[feature])\n",
                "    chi2_val, p, dof, expected = stats.chi2_contingency(cont_table.values, correction=False)\n",
                "    \n",
                "    print(f'Chi2 value for feature \"{feature}\": {chi2_val:.4f}')\n",
                "    \n",
                "    if(p \u003c ALPHA): \n",
                "        filtered_features.append(feature)\n",
                "        print(f'Reject the Null Hypothesis for feature \"{feature}\", p-value {p:.4f}\\n')\n",
                "    else:\n",
                "        print(f'Fail to reject the Null Hypothesis for feature \"{feature}\", p-value {p:.4f}\\n')\n",
                "        \n",
                "print('Feature set after filtering with Chi-square test:', filtered_features)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## \u003cu\u003eConcept: Feature filtering based on Mutual Information for classification\u003c/u\u003e\n",
                "\n",
                "In a similar fashion, we can use Mutual Information (MI) as the metric to evaluate how well-correlated the feature is with the class if the feature is a discrete variable. We will use the in-built `mutual_info_classif` function from `sklearn.feature_selection` module to calculate this score for each feature, and will include / exclude that feature depending on how high the MI is. Note that `sklearn`'s implementation of MI uses the natural logarithm instead of base 2."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "MI value for feature \"HighSales\": 0.2911\nMI value for feature \"HasSequel\": 0.1777\n\nFeature set after filtering with MI: ['HighSales']\n"
                }
            ],
            "source": [
                "from sklearn.feature_selection import mutual_info_classif\n",
                "\n",
                "filtered_features = []\n",
                "\n",
                "# Similar to ALPHA in Chi-square testing, we select a threshold level for accepting / rejecting features\n",
                "THRESHOLD = 0.2\n",
                "\n",
                "mi_arr = mutual_info_classif(X=features, y=class_label, discrete_features=True)\n",
                "\n",
                "for feature, mi in zip(features.columns, mi_arr):\n",
                "    print(f'MI value for feature \"{feature}\": {mi:.4f}')\n",
                "    \n",
                "    if(mi \u003e= THRESHOLD): \n",
                "        filtered_features.append(feature)\n",
                "        \n",
                "print('\\nFeature set after filtering with MI:', filtered_features)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Evaluation method\n",
                "\n",
                "## \u003cu\u003e Concept: $k$-fold Cross Validation (CV)\u003c/u\u003e\n",
                "- The approach randomly divides the dataset into $k$ approximately equal \"folds\" or \"partitions\".\n",
                "- Each of these \"folds\" is then used as an evaluation set in $k$ different iterations. \n",
                "- That is, each iteration of $k$-fold CV will have different \"folds\" taking turns at being the evaluation set.\n",
                "\n",
                "For example, if we had $k=3$, then:\n",
                "- The first iteration involves having \"folds\" 1 \u0026 2 for train, with 3 for evaluation.\n",
                "- In the next iteration, we might have \"folds\" 1 \u0026 3 for train, with 2 for evaluation.\n",
                "- (and so on...)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Discussion Question:**\n",
                "- Why do we need to do $k$-fold CV when we have techniques such as holdout (train-test split)?\n",
                "- What are the pros and cons of $k$-fold CV"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Answer:**\n",
                "- The common train-test split is unreliable due to some factors such as a fixed random seed. You may end up with biased labels or data points in specific splits which can lead to poor model fitting or over fitting.\n",
                "- $k$-fold CV overcomes this by using every partition for training and testing, then, taking the average performance for a more reliable accuracy.\n",
                "- However, $k$-fold CV is much slower in run-time as you need to re-train and re-test the model several times."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "\u003cdiv\u003e\n",
                            "\u003cstyle scoped\u003e\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "\u003c/style\u003e\n",
                            "\u003ctable border=\"1\" class=\"dataframe\"\u003e\n",
                            "  \u003cthead\u003e\n",
                            "    \u003ctr style=\"text-align: right;\"\u003e\n",
                            "      \u003cth\u003e\u003c/th\u003e\n",
                            "      \u003cth\u003ereview\u003c/th\u003e\n",
                            "      \u003cth\u003esentiment\u003c/th\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "  \u003c/thead\u003e\n",
                            "  \u003ctbody\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e0\u003c/th\u003e\n",
                            "      \u003ctd\u003e\"Avengers: Endgame\" is about memories, nostalg...\u003c/td\u003e\n",
                            "      \u003ctd\u003e0\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e1\u003c/th\u003e\n",
                            "      \u003ctd\u003e\"Avengers: Endgame\" is an excellent commercial...\u003c/td\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e2\u003c/th\u003e\n",
                            "      \u003ctd\u003e\"Avengers: Endgame\" is nothing short of a spec...\u003c/td\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e3\u003c/th\u003e\n",
                            "      \u003ctd\u003e\"Avengers: Endgame\" is probably one of Marvel'...\u003c/td\u003e\n",
                            "      \u003ctd\u003e1\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "    \u003ctr\u003e\n",
                            "      \u003cth\u003e4\u003c/th\u003e\n",
                            "      \u003ctd\u003e(RottenTomatoes)- They delete my reviews frequ...\u003c/td\u003e\n",
                            "      \u003ctd\u003e-1\u003c/td\u003e\n",
                            "    \u003c/tr\u003e\n",
                            "  \u003c/tbody\u003e\n",
                            "\u003c/table\u003e\n",
                            "\u003c/div\u003e"
                        ],
                        "text/plain": [
                            "                                              review  sentiment\n",
                            "0  \"Avengers: Endgame\" is about memories, nostalg...          0\n",
                            "1  \"Avengers: Endgame\" is an excellent commercial...          1\n",
                            "2  \"Avengers: Endgame\" is nothing short of a spec...          1\n",
                            "3  \"Avengers: Endgame\" is probably one of Marvel'...          1\n",
                            "4  (RottenTomatoes)- They delete my reviews frequ...         -1"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data = pd.read_csv('sentiment.csv')\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(658, 6456)\n"
                },
                {
                    "data": {
                        "text/plain": [
                            "\u003c658x6456 sparse matrix of type '\u003cclass 'numpy.int64'\u003e'\n",
                            "\twith 31366 stored elements in Compressed Sparse Row format\u003e"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "import scipy\n",
                "\n",
                "# create our X and y features\n",
                "X = data['review']\n",
                "y = data['sentiment']\n",
                "\n",
                "# vectorize our X matrix (bag-of-words format)\n",
                "vectorizer = CountVectorizer(stop_words='english')\n",
                "X = vectorizer.fit_transform(X)\n",
                "\n",
                "print(X.shape)\n",
                "X"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It's worth noting that we have a _sparse matrix_. What does this mean?\n",
                "\n",
                "If you want to \"view\" it and convert it back to a _dense_ matrix, see the following example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
                            "        [0, 0, 0, ..., 0, 0, 0],\n",
                            "        [0, 0, 0, ..., 0, 0, 0],\n",
                            "        ...,\n",
                            "        [0, 0, 0, ..., 0, 0, 0],\n",
                            "        [0, 0, 0, ..., 0, 0, 0],\n",
                            "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X = scipy.sparse.csr_matrix.todense(X)\n",
                "X"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5-fold cross validation with 5-NN classifier "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import KFold\n",
                "\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
                "from sklearn.metrics import accuracy_score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set k=5 value for k-fold CV\n",
                "k = 5\n",
                "\n",
                "kf_CV = KFold(n_splits=k, shuffle=True, random_state=42)\n",
                "results = []"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The result is a generator object of `k` tuples in the form of (list of train indices, list of test indices). \n",
                "\n",
                "So, the idea is that we will grab the indices generated by the `kfold` and then subset `X` and `y` to get `X_train`, `X_test`, `y_train`, `y_test`. \n",
                "\n",
                "Note that this has to be done manually, as opposed to the normal use of `train_test_split`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "C:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\n"
                }
            ],
            "source": [
                "for train_idx, test_idx in kf_CV.split(X):\n",
                "    # train-test split\n",
                "    X_train, X_test = X[train_idx], X[test_idx]\n",
                "    y_train, y_test = y[train_idx], y[test_idx]\n",
                "    \n",
                "    # Preprocessing\n",
                "    # 1. Standardise the data\n",
                "    scaler = StandardScaler().fit(X_train)\n",
                "    X_train = scaler.transform(X_train)\n",
                "    X_test = scaler.transform(X_test)\n",
                "    \n",
                "    # Training\n",
                "    knn = KNN(n_neighbors=5)\n",
                "    knn.fit(X_train, y_train)    \n",
                "    \n",
                "    # Predictions\n",
                "    y_pred = knn.predict(X_test)\n",
                "    results.append(accuracy_score(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Average Accuracy: 0.4954661114966458\n"
                }
            ],
            "source": [
                "print(f\"Average Accuracy: {np.mean(results)}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cblockquote style=\"padding: 10px; background-color: #ebf5fb;\"\u003e\n",
                "\n",
                "## Class Discussion Questions\n",
                "1. What happens when we have diferent values of $k$ or change the random seed?\n",
                "2. What might be an optimal value of $k$ for this dataset?\n",
                "3. Is a large $k$ always good?\n",
                "\n",
                "**Answer:**  \n",
                "- _Generally, larger values of $k$ is useful for getting more accurate results as we have more training data._\n",
                "- _For example, if $k$ were 2 or 3, we would end up with a 50/50 or 66/34 split which might be ineffective._\n",
                "- _However, if we choose $k$ to be too large, it will take far longer to process and retrain the model._\n",
                "- _To further improve this, there are techniques such as stratified $k$-fold CV or repeated $k$-fold CV._"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Performance metrics for imbalanced classification\n",
                "\n",
                "Imbalanced classification is an issue in ML classification when there is an unequal distribution of classes in the training dataset. This results in models that have poor predictive performance, specifically for the minority class.\n",
                "\n",
                "So far, we have only used accuracy as the sole metric for evaluating the performance of a classifer. In the following example with a heavily imbalanced subset of the `sentiment` dataset, we will see that it is a misleading indicator of performance on imbalanced problems. Furthermore, we will discuss some alternative metrics, namely recall, precision and F1 score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "-1    360\n 1     40\nName: sentiment, dtype: int64\n"
                },
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": [
                            "\u003cFigure size 432x288 with 1 Axes\u003e"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import scipy.sparse\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "\n",
                "# Load the imbalanced dataset\n",
                "imbalance = pd.read_csv('sentiment_imbalance.csv')\n",
                "\n",
                "# Check the class label to see that it is imbalanced classification (N=400)\n",
                "print(imbalance['sentiment'].value_counts())\n",
                "imbalance.hist('sentiment')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Number of rows \u0026 columns: (400, 4034)\n"
                }
            ],
            "source": [
                "# Get X, y\n",
                "X_imb = imbalance['review']\n",
                "y_imb = np.array(imbalance['sentiment'])\n",
                "\n",
                "# CountVectorizer\n",
                "vectorizer = CountVectorizer(stop_words='english')\n",
                "X_imb = vectorizer.fit_transform(X_imb) # Encoding text into BoW format and treat them as nominal features\n",
                "print('Number of rows \u0026 columns:', X_imb.shape)\n",
                "X_imb = scipy.sparse.csr_matrix.todense(X_imb)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Distribution of test classes:\n"
                },
                {
                    "data": {
                        "text/plain": [
                            "-1    70\n",
                            " 1    10\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Train the 5-NN model on a single holdout\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn import neighbors\n",
                "\n",
                "X_imb_train, X_imb_test, y_imb_train, y_imb_test = train_test_split(X_imb, y_imb, train_size=0.8, random_state=42)\n",
                "\n",
                "print('Distribution of test classes:')\n",
                "pd.Series(y_imb_test).value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy: 0.875\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "C:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\n"
                }
            ],
            "source": [
                "knn = KNN(n_neighbors=5)\n",
                "knn.fit(X_imb_train, y_imb_train)\n",
                "y_imb_pred=knn.predict(X_imb_test)\n",
                "\n",
                "print('Accuracy:', accuracy_score(y_imb_test, y_imb_pred))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Remember that we have 70 test instances with `-1` class, and only 10 with `1` class (minority class). Just looking at the accuracy score of `0.875`, it looks like the model correctly predicted 70 out of 80 testing instances, which is great. But let's take a look at the confusion matrix to drill down its performance for each class:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": [
                            "\u003cFigure size 432x288 with 2 Axes\u003e"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
                "\n",
                "# Confusion matrix\n",
                "cm = confusion_matrix(y_imb_test, y_imb_pred, labels=knn.classes_)\n",
                "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn.classes_).plot()\n",
                "plt.title('Confusion matrix for imbalanced dataset')\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As you can see, even though the model correctly predicted 70 instances, it only correctly predicted 2/10 minority class instances. In fact, the model only predicted 4 instances to be class `1`, which means that it is not a great model at all! Let's calculate some alternative metrics to evaluate this model using the `sklearn.metrics` module:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Recall: 0.2\nPrecision: 0.5\nF1: 0.28571428571428575\n"
                }
            ],
            "source": [
                "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
                "\n",
                "print('Recall:', recall_score(y_imb_test, y_imb_pred))\n",
                "print('Precision:', precision_score(y_imb_test, y_imb_pred))\n",
                "print('F1:', f1_score(y_imb_test, y_imb_pred))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cblockquote style=\"padding: 10px; background-color: #ebf5fb;\"\u003e\n",
                "\n",
                "## Class Discussion Questions\n",
                "1. Using the values from the confusion matrix, show all calculations to confirm the `sklearn` recall, precision, and f1 scores (refer to the formulas in the lecture slides)\n",
                "2. When do you prefer recall over precision? When do you prefer precision over recall?\n",
                "3. In the current use case (evaluating the performance of a sentiment predictor), which metric is the most appropriate and why?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## \u003cu\u003e Concept: Bootstrapping\u003c/u\u003e\n",
                "\n",
                "Similar to how we can combine k-fold CV to get an average accuracy score, we can use k-fold CV with any of these alternative metrics. And of course, you can use multiple metrics to evaluate a single model to identify its strengths and weaknesses in a more holistic picture.\n",
                "\n",
                "For imbalanced datasets, however, we may also use **bootstrapping** instead of k-fold CV to get a range of performance scores. In this model evaluation method, you draw multiple training sets by random sampling from the training data wit replacement; these samples are called bootstrap samples. You can use `resample()` method in scikit-learn \n",
                "https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html\n",
                "\n",
                "You train the model multiple times with the bootstrap samples.\n",
                "You obtain the performance scores from the corresponding test sets.\n",
                "The test set, for a bootstrap sample, contain observations not in (unseen) the bootstrap sample.\n",
                "\n",
                "This set of scores give you a range of performance scores, from which you can calculate mean, sd and confidence interval of the performance.\n",
                "They provide a distribution for the perfomance of the classification model.\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Unlike k-fold, bootstrapping doesn't have an off-the-shelf function in `scikit-learn`, so we have to implement them with the `resample()` utility function. In the following section, we will show how you can use this function to generate repeated samples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "([172, 47, 117, 192, 323, 251, 195, 359, 9, 211, 277, 242, 292, 87, 70, 88, 396, 314, 193, 39, 87, 174, 88, 337, 165, 25, 333, 72, 265, 115, 243, 197, 335, 338, 99, 177, 243, 285, 147, 147, 398, 288, 265, 185, 127, 32, 31, 202, 244, 151, 163, 370, 183, 28, 290, 128, 128, 53, 389, 38, 244, 273, 335, 388, 105, 42, 31, 376, 257, 321, 57, 291, 358, 119, 267, 82, 91, 384, 398, 99, 53, 396, 121, 84, 203, 324, 262, 47, 127, 131, 356, 180, 334, 143, 148, 227, 279, 207, 397, 373, 341, 48, 305, 69, 169, 163, 95, 197, 94, 256, 369, 178, 292, 304, 349, 387, 98, 42, 368, 201, 383, 0, 394, 370, 43, 383, 23, 187, 130, 377, 98, 62, 222, 123, 82, 227, 148, 209, 50, 270, 41, 58, 193, 36, 266, 86, 43, 360, 11, 258, 307, 80, 32, 182, 128, 294, 275, 174, 42, 371, 184, 77, 286, 280, 125, 258, 3, 94, 226, 363, 269, 368, 296, 328, 19, 95, 328, 248, 180, 323, 317, 270, 352, 260, 237, 139, 86, 377, 109, 331, 184, 16, 152, 149, 110, 25, 377, 374, 117, 83, 161, 360, 228, 251, 121, 326, 287, 13, 327, 184, 152, 79, 41, 274, 40, 207, 267, 166, 111, 349, 129, 223, 374, 300, 216, 381, 24, 67, 259, 234, 204, 291, 214, 189, 197, 215, 43, 32, 11, 104, 212, 138, 182, 125, 156, 111, 258, 27, 217, 151, 309, 307, 174, 148, 29, 67, 35, 295, 393, 73, 297, 387, 302, 218, 364, 259, 287, 265, 394, 27, 199, 61, 341, 353, 44, 290, 88, 33, 133, 232, 255, 36, 256, 290, 197, 382, 254, 80, 136, 189, 129, 209, 368, 291, 376, 347, 168, 372, 292, 176, 25, 323, 359, 291, 114, 286, 29, 241, 289, 146, 273, 221, 340, 2, 69, 357, 396, 44, 373, 253, 322, 111, 91, 341, 39, 150, 145, 198, 274, 348, 43, 83, 297, 93, 174, 201, 345, 329, 28, 209, 105, 384, 63, 16, 106, 164, 94, 24, 116, 191, 195, 307, 136, 347, 93, 379, 238, 87, 160, 147, 72, 87, 13, 314, 81, 120, 372, 320, 203, 220, 281, 288, 270, 284, 276, 324, 22, 227, 378, 83, 135, 61, 141, 5, 256, 136, 207, 139, 4, 348, 282, 74, 308, 219, 307, 227, 361, 274, 373, 290], [1, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 26, 30, 34, 37, 45, 46, 49, 51, 52, 54, 55, 56, 59, 60, 64, 65, 66, 68, 71, 75, 76, 78, 85, 89, 90, 92, 96, 97, 100, 101, 102, 103, 107, 108, 112, 113, 118, 122, 124, 126, 132, 134, 137, 140, 142, 144, 153, 154, 155, 157, 158, 159, 162, 167, 170, 171, 173, 175, 179, 181, 186, 188, 190, 194, 196, 200, 205, 206, 208, 210, 213, 224, 225, 229, 230, 231, 233, 235, 236, 239, 240, 245, 246, 247, 249, 250, 252, 261, 263, 264, 268, 271, 272, 278, 283, 293, 298, 299, 301, 303, 306, 310, 311, 312, 313, 315, 316, 318, 319, 325, 330, 332, 336, 339, 342, 343, 344, 346, 350, 351, 354, 355, 362, 365, 366, 367, 375, 380, 385, 386, 390, 391, 392, 395, 399])\n"
                }
            ],
            "source": [
                "# scikit-learn bootstrap\n",
                "from sklearn.utils import resample\n",
                "\n",
                "n = X_imb.shape[0]\n",
                "# data index\n",
                "dataidx = range(n)\n",
                "\n",
                "# number of bootstrap samples\n",
                "k = 10\n",
                "\n",
                "# a list to store the bootstrap sample indices\n",
                "bs = []\n",
                "\n",
                "# Perform bootstrapping k times\n",
                "for j in range(k):\n",
                "    \n",
                "    # prepare bootstrap sample\n",
                "    boot_index = resample(range(n), replace=True, n_samples=n, random_state=j)\n",
                "    # out of bag observations\n",
                "    oob_index = [x for x in range(n) if x not in boot_index]\n",
                "    bs.append((boot_index, oob_index))\n",
                "    \n",
                "# Note that the size of oob_index list is different for each bootstrapping,\n",
                "# but the size of boot_index list is always the same (n)\n",
                "print(bs[0])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In practice, you don't need to generate the indices separately, but you can incorporate the resampling inside the for loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "C:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\nC:\\Users\\Diamo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n  warnings.warn(\n"
                }
            ],
            "source": [
                "# Storing the metrics for each dataset\n",
                "accuracies = []\n",
                "precisions = []\n",
                "recalls = []\n",
                "f1s = []\n",
                "\n",
                "# Loop through each dataset, split data based on bootstrapping indices + fit model + evaluate\n",
                "for k in range(10):\n",
                "    # prepare bootstrap sample\n",
                "    boot_index = resample(range(n), replace=True, n_samples=n, random_state=k)\n",
                "    # out of bag observations\n",
                "    oob_index = [x for x in range(n) if x not in boot_index]\n",
                "    # Split datasets\n",
                "    X_imb_train = X_imb[boot_index,:]\n",
                "    X_imb_test = X_imb[oob_index,:]\n",
                "    y_imb_train = y_imb[boot_index]\n",
                "    y_imb_test = y_imb[oob_index]\n",
                "    \n",
                "    # Train\n",
                "    knn = KNN(n_neighbors=5)\n",
                "    knn.fit(X_imb_train, y_imb_train)\n",
                "    \n",
                "    # Predict\n",
                "    y_imb_pred=knn.predict(X_imb_test)\n",
                "    \n",
                "    # Evaluate\n",
                "    accuracies.append(accuracy_score(y_imb_test, y_imb_pred))\n",
                "    recalls.append(recall_score(y_imb_test, y_imb_pred))\n",
                "    precisions.append(precision_score(y_imb_test, y_imb_pred))\n",
                "    f1s.append(f1_score(y_imb_test, y_imb_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy from each bootstrap sample: [0.8843537414965986, 0.8723404255319149, 0.8785714285714286, 0.8581081081081081, 0.8657718120805369, 0.8308823529411765, 0.7569444444444444, 0.9057971014492754, 0.7702702702702703, 0.7516339869281046]\nMean accuracy from all bootstrap samples: 0.9305192968690954\n"
                }
            ],
            "source": [
                "print(\"Accuracy from each bootstrap sample:\", accuracies)\n",
                "#Display average of accuracy scores\n",
                "avg_acc_score = np.mean(accuracies)\n",
                "print(\"Mean accuracy from all bootstrap samples:\", avg_acc_score)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Precision from each bootstrap sample: [0.4, 0.3333333333333333, 0.5, 0.14285714285714285, 0.2222222222222222, 0.1, 0.2, 0.2, 0.1935483870967742, 0.08333333333333333]\nMean precision from all bootstrap samples: 0.2639216020936451\n"
                }
            ],
            "source": [
                "print(\"Precision from each bootstrap sample:\", precisions)\n",
                "#Display average of precision scores\n",
                "avg_precision_score = np.mean(precisions)\n",
                "print(\"Mean precision from all bootstrap samples:\", avg_precision_score)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Recall from each bootstrap sample: [0.125, 0.058823529411764705, 0.4117647058823529, 0.18181818181818182, 0.4, 0.2857142857142857, 0.5, 0.1, 0.4, 0.1111111111111111]\nMean recall from all bootstrap samples: 0.2860257571041884\n"
                }
            ],
            "source": [
                "print(\"Recall from each bootstrap sample:\", recalls)\n",
                "#Display average of recall scores\n",
                "avg_recall_score = np.mean(recalls)\n",
                "print(\"Mean recall from all bootstrap samples:\", avg_recall_score)"
            ]
        }
    ]
}
