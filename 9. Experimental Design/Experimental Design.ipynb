{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\r\n",
                "import numpy as np\r\n",
                "from matplotlib import pyplot as plt\r\n",
                "import scipy.stats as stats\r\n",
                "from scipy.stats import chi2_contingency\r\n",
                "from sklearn.feature_selection import mutual_info_classif\r\n",
                "from sklearn.feature_extraction.text import CountVectorizer\r\n",
                "import scipy\r\n",
                "from sklearn.model_selection import KFold\r\n",
                "from sklearn.preprocessing import StandardScaler\r\n",
                "from sklearn.neighbors import KNeighborsClassifier as KNN\r\n",
                "from sklearn.metrics import accuracy_score\r\n",
                "import scipy.sparse\r\n",
                "from sklearn.model_selection import train_test_split\r\n",
                "from sklearn import neighbors\r\n",
                "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\r\n",
                "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\r\n",
                "from sklearn.utils import resample"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Univariate feature selection\r\n",
                "## Feature filtering based on $\\chi^2$-Test for classification\r\n",
                "\r\n",
                "To create a hypothesis test, we propose the following:\r\n",
                "1. Null Hypothesis: The feature is is not significant. In other words, the feature is useless and doesn't provide anything useful.\r\n",
                "2. Alternative Hypothesis: The feature is significant and provides useful insight statistically.\r\n",
                "\r\n",
                "To find out what hypothesis holds, we need to compute the `p-value`.\r\n",
                "- The `p-value` is the *probability* of obtaining results that are *at least as extreme* (i.e outliers) as the results observed.\r\n",
                "- These observations are under the assumption that the Null hypothesis is correct (the feature is useless).\r\n",
                "- However, if the `p-value` is small, then it means that our *observed extreme results* are very unlikely under the Null hypothesis. \r\n",
                "- Therefore, given some significance threshold $\\alpha$ (usually at 0.05), we **reject the Null hypothesis** i.f.f (if and only if) the `p-value` < $\\alpha$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HighSales</th>\n      <th>HasSequel</th>\n      <th>IsPopular</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   HighSales  HasSequel  IsPopular\n0          1          0          1\n1          1          1          1\n2          1          1          1\n3          1          0          0\n4          1          1          1\n5          0          0          0\n6          0          0          0\n7          0          0          0\n8          1          1          0\n9          0          0          0"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# this is the same table of data from above \n",
                "data = pd.DataFrame([[1,0,1], [1,1,1], [1,1,1], [1,0,0], [1,1,1], [0,0,0], [0,0,0], [0,0,0], [1,1,0], [0,0,0]], \n",
                "                    columns=['HighSales','HasSequel','IsPopular'])\n",
                "\n",
                "data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set our alpha significance level\n",
                "ALPHA = 0.05\n",
                "\n",
                "# get our features and class label\n",
                "features = data[['HighSales','HasSequel']]\n",
                "class_label = data['IsPopular']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>HighSales</th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n    <tr>\n      <th>IsPopular</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "HighSales  0  1\nIsPopular      \n0          4  2\n1          0  4"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "cont_table = pd.crosstab(class_label, features['HighSales'])\n",
                "cont_table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "4.444444444444445\n",
                        "0.03501498101966245\n",
                        "1\n",
                        "[[2.4 3.6]\n",
                        " [1.6 2.4]]\n"
                    ]
                }
            ],
            "source": [
                "chi2_val, p, dof, expected_values = stats.chi2_contingency(cont_table.values, correction=False)\n",
                "print(chi2_val)\n",
                "print(p)\n",
                "print(dof)\n",
                "\n",
                "# this is the expected values for the Chi^2 test\n",
                "print(expected_values)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "From above, we can see that our `p-value` is $\\approx0.035$ which is less than $\\alpha=0.05$. Therefore, we would **reject the Null Hypothesis**.\n",
                "\n",
                "To do both `HighSales` and `HasSequel` together, we can use a `for` loop as shown below:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Chi2 value for feature \"HighSales\": 4.4444\n",
                        "Reject the Null Hypothesis for feature \"HighSales\", p-value 0.0350\n",
                        "\n",
                        "Chi2 value for feature \"HasSequel\": 3.4028\n",
                        "Fail to reject the Null Hypothesis for feature \"HasSequel\", p-value 0.0651\n",
                        "\n",
                        "Feature set after filtering with Chi-square test: ['HighSales']\n"
                    ]
                }
            ],
            "source": [
                "filtered_features = []\n",
                "\n",
                "for feature in ('HighSales','HasSequel'):\n",
                "    cont_table = pd.crosstab(class_label, features[feature])\n",
                "    chi2_val, p, dof, expected = stats.chi2_contingency(cont_table.values, correction=False)\n",
                "    \n",
                "    print(f'Chi2 value for feature \"{feature}\": {chi2_val:.4f}')\n",
                "    \n",
                "    if(p < ALPHA): \n",
                "        filtered_features.append(feature)\n",
                "        print(f'Reject the Null Hypothesis for feature \"{feature}\", p-value {p:.4f}\\n')\n",
                "    else:\n",
                "        print(f'Fail to reject the Null Hypothesis for feature \"{feature}\", p-value {p:.4f}\\n')\n",
                "        \n",
                "print('Feature set after filtering with Chi-square test:', filtered_features)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Feature filtering based on Mutual Information for classification\r\n",
                "\r\n",
                "In a similar fashion, we can use Mutual Information (MI) as the metric to evaluate how well-correlated the feature is with the class if the feature is a discrete variable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "MI value for feature \"HighSales\": 0.2911\n",
                        "MI value for feature \"HasSequel\": 0.1777\n",
                        "\n",
                        "Feature set after filtering with MI: ['HighSales']\n"
                    ]
                }
            ],
            "source": [
                "filtered_features = []\r\n",
                "\r\n",
                "# Similar to ALPHA in Chi-square testing, we select a threshold level for accepting / rejecting features\r\n",
                "THRESHOLD = 0.2\r\n",
                "\r\n",
                "mi_arr = mutual_info_classif(X=features, y=class_label, discrete_features=True)\r\n",
                "\r\n",
                "for feature, mi in zip(features.columns, mi_arr):\r\n",
                "    print(f'MI value for feature \"{feature}\": {mi:.4f}')\r\n",
                "    \r\n",
                "    if(mi >= THRESHOLD): \r\n",
                "        filtered_features.append(feature)\r\n",
                "        \r\n",
                "print('\\nFeature set after filtering with MI:', filtered_features)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Evaluation method\n",
                "\n",
                "## <u> Concept: $k$-fold Cross Validation (CV)</u>\n",
                "- The approach randomly divides the dataset into $k$ approximately equal \"folds\" or \"partitions\".\n",
                "- Each of these \"folds\" is then used as an evaluation set in $k$ different iterations. \n",
                "- That is, each iteration of $k$-fold CV will have different \"folds\" taking turns at being the evaluation set.\n",
                "\n",
                "For example, if we had $k=3$, then:\n",
                "- The first iteration involves having \"folds\" 1 & 2 for train, with 3 for evaluation.\n",
                "- In the next iteration, we might have \"folds\" 1 & 3 for train, with 2 for evaluation.\n",
                "- (and so on...)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- The common train-test split is unreliable due to some factors such as a fixed random seed. You may end up with biased labels or data points in specific splits which can lead to poor model fitting or over fitting.\r\n",
                "- $k$-fold CV overcomes this by using every partition for training and testing, then, taking the average performance for a more reliable accuracy.\r\n",
                "- However, $k$-fold CV is much slower in run-time as you need to re-train and re-test the model several times."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"Avengers: Endgame\" is about memories, nostalg...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"Avengers: Endgame\" is an excellent commercial...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"Avengers: Endgame\" is nothing short of a spec...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"Avengers: Endgame\" is probably one of Marvel'...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(RottenTomatoes)- They delete my reviews frequ...</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "                                              review  sentiment\n0  \"Avengers: Endgame\" is about memories, nostalg...          0\n1  \"Avengers: Endgame\" is an excellent commercial...          1\n2  \"Avengers: Endgame\" is nothing short of a spec...          1\n3  \"Avengers: Endgame\" is probably one of Marvel'...          1\n4  (RottenTomatoes)- They delete my reviews frequ...         -1"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data = pd.read_csv('sentiment.csv')\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(658, 6456)\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": "<658x6456 sparse matrix of type '<class 'numpy.int64'>'\n\twith 31366 stored elements in Compressed Sparse Row format>"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# create our X and y features\r\n",
                "X = data['review']\r\n",
                "y = data['sentiment']\r\n",
                "\r\n",
                "# vectorize our X matrix (bag-of-words format)\r\n",
                "vectorizer = CountVectorizer(stop_words='english')\r\n",
                "X = vectorizer.fit_transform(X)\r\n",
                "\r\n",
                "print(X.shape)\r\n",
                "X"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "matrix([[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X = scipy.sparse.csr_matrix.todense(X)\n",
                "X"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5-fold cross validation with 5-NN classifier "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set k=5 value for k-fold CV\n",
                "k = 5\n",
                "\n",
                "kf_CV = KFold(n_splits=k, shuffle=True, random_state=42)\n",
                "results = []"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The result is a generator object of `k` tuples in the form of (list of train indices, list of test indices). \n",
                "\n",
                "So, the idea is that we will grab the indices generated by the `kfold` and then subset `X` and `y` to get `X_train`, `X_test`, `y_train`, `y_test`. \n",
                "\n",
                "Note that this has to be done manually, as opposed to the normal use of `train_test_split`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "for train_idx, test_idx in kf_CV.split(X):\n",
                "    # train-test split\n",
                "    X_train, X_test = X[train_idx], X[test_idx]\n",
                "    y_train, y_test = y[train_idx], y[test_idx]\n",
                "    \n",
                "    # Preprocessing\n",
                "    # 1. Standardise the data\n",
                "    scaler = StandardScaler().fit(X_train)\n",
                "    X_train = scaler.transform(X_train)\n",
                "    X_test = scaler.transform(X_test)\n",
                "    \n",
                "    # Training\n",
                "    knn = KNN(n_neighbors=5)\n",
                "    knn.fit(X_train, y_train)    \n",
                "    \n",
                "    # Predictions\n",
                "    y_pred = knn.predict(X_test)\n",
                "    results.append(accuracy_score(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Average Accuracy: 0.4954661114966458\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Average Accuracy: {np.mean(results)}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- _Generally, larger values of $k$ is useful for getting more accurate results as we have more training data._\r\n",
                "- _For example, if $k$ were 2 or 3, we would end up with a 50/50 or 66/34 split which might be ineffective._\r\n",
                "- _However, if we choose $k$ to be too large, it will take far longer to process and retrain the model._\r\n",
                "- _To further improve this, there are techniques such as stratified $k$-fold CV or repeated $k$-fold CV._"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Performance metrics for imbalanced classification\r\n",
                "\r\n",
                " Alternative metrics, namely recall, precision and F1 score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "-1    360\n",
                        " 1     40\n",
                        "Name: sentiment, dtype: int64\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Load the imbalanced dataset\r\n",
                "imbalance = pd.read_csv('sentiment_imbalance.csv')\r\n",
                "\r\n",
                "# Check the class label to see that it is imbalanced classification (N=400)\r\n",
                "print(imbalance['sentiment'].value_counts())\r\n",
                "imbalance.hist('sentiment')\r\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of rows & columns: (400, 4034)\n"
                    ]
                }
            ],
            "source": [
                "# Get X, y\n",
                "X_imb = imbalance['review']\n",
                "y_imb = np.array(imbalance['sentiment'])\n",
                "\n",
                "# CountVectorizer\n",
                "vectorizer = CountVectorizer(stop_words='english')\n",
                "X_imb = vectorizer.fit_transform(X_imb) # Encoding text into BoW format and treat them as nominal features\n",
                "print('Number of rows & columns:', X_imb.shape)\n",
                "X_imb = scipy.sparse.csr_matrix.todense(X_imb)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Distribution of test classes:\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": "-1    70\n 1    10\ndtype: int64"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Train the 5-NN model on a single holdout\r\n",
                "X_imb_train, X_imb_test, y_imb_train, y_imb_test = train_test_split(X_imb, y_imb, train_size=0.8, random_state=42)\r\n",
                "\r\n",
                "print('Distribution of test classes:')\r\n",
                "pd.Series(y_imb_test).value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Accuracy: 0.875\n"
                    ]
                }
            ],
            "source": [
                "knn = KNN(n_neighbors=5)\n",
                "knn.fit(X_imb_train, y_imb_train)\n",
                "y_imb_pred=knn.predict(X_imb_test)\n",
                "\n",
                "print('Accuracy:', accuracy_score(y_imb_test, y_imb_pred))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Remember that we have 70 test instances with `-1` class, and only 10 with `1` class (minority class). Just looking at the accuracy score of `0.875`, it looks like the model correctly predicted 70 out of 80 testing instances, which is great. But let's take a look at the confusion matrix to drill down its performance for each class:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 2 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Confusion matrix\r\n",
                "cm = confusion_matrix(y_imb_test, y_imb_pred, labels=knn.classes_)\r\n",
                "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn.classes_).plot()\r\n",
                "plt.title('Confusion matrix for imbalanced dataset')\r\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As you can see, even though the model correctly predicted 70 instances, it only correctly predicted 2/10 minority class instances. In fact, the model only predicted 4 instances to be class `1`, which means that it is not a great model at all! Let's calculate some alternative metrics to evaluate this model using the `sklearn.metrics` module:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Recall: 0.2\n",
                        "Precision: 0.5\n",
                        "F1: 0.28571428571428575\n"
                    ]
                }
            ],
            "source": [
                "print('Recall:', recall_score(y_imb_test, y_imb_pred))\r\n",
                "print('Precision:', precision_score(y_imb_test, y_imb_pred))\r\n",
                "print('F1:', f1_score(y_imb_test, y_imb_pred))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bootstrapping\r\n",
                "\r\n",
                "For imbalanced datasets, however, we may also use **bootstrapping** instead of k-fold CV to get a range of performance scores. In this model evaluation method, you draw multiple training sets by random sampling from the training data wit replacement; these samples are called bootstrap samples. \r\n",
                "You train the model multiple times with the bootstrap samples.\r\n",
                "You obtain the performance scores from the corresponding test sets.\r\n",
                "The test set, for a bootstrap sample, contain observations not in (unseen) the bootstrap sample.\r\n",
                "\r\n",
                "This set of scores give you a range of performance scores, from which you can calculate mean, sd and confidence interval of the performance.\r\n",
                "They provide a distribution for the perfomance of the classification model.\r\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Unlike k-fold, bootstrapping doesn't have an off-the-shelf function in `scikit-learn`, so we have to implement them with the `resample()` utility function. In the following section, we will show how you can use this function to generate repeated samples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "([172, 47, 117, 192, 323, 251, 195, 359, 9, 211, 277, 242, 292, 87, 70, 88, 396, 314, 193, 39, 87, 174, 88, 337, 165, 25, 333, 72, 265, 115, 243, 197, 335, 338, 99, 177, 243, 285, 147, 147, 398, 288, 265, 185, 127, 32, 31, 202, 244, 151, 163, 370, 183, 28, 290, 128, 128, 53, 389, 38, 244, 273, 335, 388, 105, 42, 31, 376, 257, 321, 57, 291, 358, 119, 267, 82, 91, 384, 398, 99, 53, 396, 121, 84, 203, 324, 262, 47, 127, 131, 356, 180, 334, 143, 148, 227, 279, 207, 397, 373, 341, 48, 305, 69, 169, 163, 95, 197, 94, 256, 369, 178, 292, 304, 349, 387, 98, 42, 368, 201, 383, 0, 394, 370, 43, 383, 23, 187, 130, 377, 98, 62, 222, 123, 82, 227, 148, 209, 50, 270, 41, 58, 193, 36, 266, 86, 43, 360, 11, 258, 307, 80, 32, 182, 128, 294, 275, 174, 42, 371, 184, 77, 286, 280, 125, 258, 3, 94, 226, 363, 269, 368, 296, 328, 19, 95, 328, 248, 180, 323, 317, 270, 352, 260, 237, 139, 86, 377, 109, 331, 184, 16, 152, 149, 110, 25, 377, 374, 117, 83, 161, 360, 228, 251, 121, 326, 287, 13, 327, 184, 152, 79, 41, 274, 40, 207, 267, 166, 111, 349, 129, 223, 374, 300, 216, 381, 24, 67, 259, 234, 204, 291, 214, 189, 197, 215, 43, 32, 11, 104, 212, 138, 182, 125, 156, 111, 258, 27, 217, 151, 309, 307, 174, 148, 29, 67, 35, 295, 393, 73, 297, 387, 302, 218, 364, 259, 287, 265, 394, 27, 199, 61, 341, 353, 44, 290, 88, 33, 133, 232, 255, 36, 256, 290, 197, 382, 254, 80, 136, 189, 129, 209, 368, 291, 376, 347, 168, 372, 292, 176, 25, 323, 359, 291, 114, 286, 29, 241, 289, 146, 273, 221, 340, 2, 69, 357, 396, 44, 373, 253, 322, 111, 91, 341, 39, 150, 145, 198, 274, 348, 43, 83, 297, 93, 174, 201, 345, 329, 28, 209, 105, 384, 63, 16, 106, 164, 94, 24, 116, 191, 195, 307, 136, 347, 93, 379, 238, 87, 160, 147, 72, 87, 13, 314, 81, 120, 372, 320, 203, 220, 281, 288, 270, 284, 276, 324, 22, 227, 378, 83, 135, 61, 141, 5, 256, 136, 207, 139, 4, 348, 282, 74, 308, 219, 307, 227, 361, 274, 373, 290], [1, 6, 7, 8, 10, 12, 14, 15, 17, 18, 20, 21, 26, 30, 34, 37, 45, 46, 49, 51, 52, 54, 55, 56, 59, 60, 64, 65, 66, 68, 71, 75, 76, 78, 85, 89, 90, 92, 96, 97, 100, 101, 102, 103, 107, 108, 112, 113, 118, 122, 124, 126, 132, 134, 137, 140, 142, 144, 153, 154, 155, 157, 158, 159, 162, 167, 170, 171, 173, 175, 179, 181, 186, 188, 190, 194, 196, 200, 205, 206, 208, 210, 213, 224, 225, 229, 230, 231, 233, 235, 236, 239, 240, 245, 246, 247, 249, 250, 252, 261, 263, 264, 268, 271, 272, 278, 283, 293, 298, 299, 301, 303, 306, 310, 311, 312, 313, 315, 316, 318, 319, 325, 330, 332, 336, 339, 342, 343, 344, 346, 350, 351, 354, 355, 362, 365, 366, 367, 375, 380, 385, 386, 390, 391, 392, 395, 399])\n"
                    ]
                }
            ],
            "source": [
                "n = X_imb.shape[0]\r\n",
                "# data index\r\n",
                "dataidx = range(n)\r\n",
                "\r\n",
                "# number of bootstrap samples\r\n",
                "k = 10\r\n",
                "\r\n",
                "# a list to store the bootstrap sample indices\r\n",
                "bs = []\r\n",
                "\r\n",
                "# Perform bootstrapping k times\r\n",
                "for j in range(k):\r\n",
                "    \r\n",
                "    # prepare bootstrap sample\r\n",
                "    boot_index = resample(range(n), replace=True, n_samples=n, random_state=j)\r\n",
                "    # out of bag observations\r\n",
                "    oob_index = [x for x in range(n) if x not in boot_index]\r\n",
                "    bs.append((boot_index, oob_index))\r\n",
                "    \r\n",
                "# Note that the size of oob_index list is different for each bootstrapping,\r\n",
                "# but the size of boot_index list is always the same (n)\r\n",
                "print(bs[0])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In practice, you don't need to generate the indices separately, but you can incorporate the resampling inside the for loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Storing the metrics for each dataset\n",
                "accuracies = []\n",
                "precisions = []\n",
                "recalls = []\n",
                "f1s = []\n",
                "\n",
                "# Loop through each dataset, split data based on bootstrapping indices + fit model + evaluate\n",
                "for k in range(10):\n",
                "    # prepare bootstrap sample\n",
                "    boot_index = resample(range(n), replace=True, n_samples=n, random_state=k)\n",
                "    # out of bag observations\n",
                "    oob_index = [x for x in range(n) if x not in boot_index]\n",
                "    # Split datasets\n",
                "    X_imb_train = X_imb[boot_index,:]\n",
                "    X_imb_test = X_imb[oob_index,:]\n",
                "    y_imb_train = y_imb[boot_index]\n",
                "    y_imb_test = y_imb[oob_index]\n",
                "    \n",
                "    # Train\n",
                "    knn = KNN(n_neighbors=5)\n",
                "    knn.fit(X_imb_train, y_imb_train)\n",
                "    \n",
                "    # Predict\n",
                "    y_imb_pred=knn.predict(X_imb_test)\n",
                "    \n",
                "    # Evaluate\n",
                "    accuracies.append(accuracy_score(y_imb_test, y_imb_pred))\n",
                "    recalls.append(recall_score(y_imb_test, y_imb_pred))\n",
                "    precisions.append(precision_score(y_imb_test, y_imb_pred))\n",
                "    f1s.append(f1_score(y_imb_test, y_imb_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Accuracy from each bootstrap sample: [0.8843537414965986, 0.8723404255319149, 0.8785714285714286, 0.8581081081081081, 0.8657718120805369, 0.8308823529411765, 0.7569444444444444, 0.9057971014492754, 0.7702702702702703, 0.7516339869281046]\n",
                        "Mean accuracy from all bootstrap samples: 0.8374673671821858\n"
                    ]
                }
            ],
            "source": [
                "print(\"Accuracy from each bootstrap sample:\", accuracies)\n",
                "#Display average of accuracy scores\n",
                "avg_acc_score = np.mean(accuracies)\n",
                "print(\"Mean accuracy from all bootstrap samples:\", avg_acc_score)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Precision from each bootstrap sample: [0.4, 0.3333333333333333, 0.5, 0.14285714285714285, 0.2222222222222222, 0.1, 0.2, 0.2, 0.1935483870967742, 0.08333333333333333]\n",
                        "Mean precision from all bootstrap samples: 0.2375294418842806\n"
                    ]
                }
            ],
            "source": [
                "print(\"Precision from each bootstrap sample:\", precisions)\n",
                "#Display average of precision scores\n",
                "avg_precision_score = np.mean(precisions)\n",
                "print(\"Mean precision from all bootstrap samples:\", avg_precision_score)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Recall from each bootstrap sample: [0.125, 0.058823529411764705, 0.4117647058823529, 0.18181818181818182, 0.4, 0.2857142857142857, 0.5, 0.1, 0.4, 0.1111111111111111]\n",
                        "Mean recall from all bootstrap samples: 0.25742318139376963\n"
                    ]
                }
            ],
            "source": [
                "print(\"Recall from each bootstrap sample:\", recalls)\n",
                "#Display average of recall scores\n",
                "avg_recall_score = np.mean(recalls)\n",
                "print(\"Mean recall from all bootstrap samples:\", avg_recall_score)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.0 64-bit",
            "metadata": {
                "interpreter": {
                    "hash": "2d04f120ef9720f2488447f7ea0097f595927923387bca235b2adec1aebe5795"
                }
            },
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}